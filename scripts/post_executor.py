#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Kåˆ—äºˆç´„æŠ•ç¨¿å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆGitHub Actionsç”¨ãƒ»éWordPressï¼‰
- Kåˆ—ä»¥é™ã®äºˆç´„æ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦è©²å½“æ™‚åˆ»ã®æŠ•ç¨¿ã‚’å®Ÿè¡Œ
- å¯¾è±¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼šSeesaa / FC2 / livedoor / Blogger
- äºˆç´„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: --window åˆ†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30åˆ†ï¼‰
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé¸æŠ: --project biggift | arigataya
- ãƒ†ã‚¹ãƒˆ: --testï¼ˆæ¥ç¶šæ¤œè¨¼ã®ã¿ã€æŠ•ç¨¿ã—ãªã„ï¼‰
"""

import os
import re
import json
import time
import random
import logging
import requests
import gspread
import xmlrpc.client
import xml.etree.ElementTree as ET
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse
from datetime import datetime, timedelta
from oauth2client.service_account import ServiceAccountCredentials
from requests.auth import HTTPBasicAuth
from xml.sax.saxutils import escape as xml_escape
import tempfile
import argparse
import traceback

# Google / Blogger
try:
    from google.oauth2.credentials import Credentials as GoogleCredentials
    from google.auth.transport.requests import Request as GoogleAuthRequest
    from googleapiclient.discovery import build as gapi_build
except Exception:
    GoogleCredentials = None
    GoogleAuthRequest = None
    gapi_build = None

# ----------------------------
# ãƒ­ã‚°è¨­å®š
# ----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ----------------------------
# ç’°å¢ƒå¤‰æ•°
# ----------------------------
SPREADSHEET_ID = os.environ.get("SPREADSHEET_ID", "1sV0r6LavB4BgU7jGaa5C-GdyogUpWr_y42a-tNZXuFo")
GOOGLE_APPLICATION_CREDENTIALS_JSON = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON", "")

# Gemini APIè¨­å®šï¼ˆã‚­ãƒ¼ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å¿œï¼‰
GEMINI_KEYS = [k for k in [
    os.environ.get("GEMINI_API_KEY_1"),
    os.environ.get("GEMINI_API_KEY_2"),
    os.environ.get("GEMINI_API_KEY_3"),
] if k]
if not GEMINI_KEYS:
    GEMINI_KEYS = ["AIzaSyBCxQruA6WrmfZHoZ6pTBPRVqkALKvdsT0"]
_gemini_idx = 0

# æŠ•ç¨¿é–“éš”ï¼ˆã‚¹ãƒ‘ãƒ å›é¿ï¼‰
MIN_INTERVAL = int(os.environ.get("POST_MIN_INTERVAL", "60"))
MAX_INTERVAL = int(os.environ.get("POST_MAX_INTERVAL", "120"))

# ----------------------------
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šï¼ˆéWordPressã®ã¿ï¼‰
# ----------------------------
NON_WP_PROJECTS = {
    "biggift": {
        "worksheet": "ãƒ“ãƒƒã‚¯ã‚®ãƒ•ãƒˆå‘ã‘",
        "platforms": ["blogger", "livedoor"],  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¯¾è±¡
        "max_posts": {"blogger": 20, "livedoor": 15}
    },
    "arigataya": {
        "worksheet": "ã‚ã‚ŠãŒãŸå±‹å‘ã‘",
        "platforms": ["seesaa", "fc2"],
        "max_posts": 20
    }
}

# ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ãƒªãƒã‚¸ãƒˆãƒªã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰ä¸Šæ›¸ãã‚’æ¨å¥¨ï¼‰
PLATFORM_CONFIGS = {
    "seesaa": {
        "endpoint": os.environ.get("SEESAA_ENDPOINT", "http://blog.seesaa.jp/rpc"),
        "username": os.environ.get("SEESAA_USERNAME", "kyuuyo.fac@gmail.com"),
        "password": os.environ.get("SEESAA_PASSWORD", "st13131094pao"),
        "blogid":   os.environ.get("SEESAA_BLOGID", "7228801"),
        "timeout":  45,
    },
    "fc2": {
        "endpoint": "https://blog.fc2.com/xmlrpc.php",
        "blog_id":  os.environ.get("FC2_BLOG_ID", "genkinka1313"),
        "username": os.environ.get("FC2_USERNAME", "esciresearch.com@gmail.com"),
        "password": os.environ.get("FC2_PASSWORD", "st13131094pao"),
        "timeout":  45,
    },
    "livedoor": {
        "root":     "https://livedoor.blogcms.jp/atompub",
        "blog_name":os.environ.get("LIVEDOOR_BLOG_NAME", "radiochildcare"),
        "user_id":  os.environ.get("LIVEDOOR_ID", "radiochildcare"),
        "api_key":  os.environ.get("LIVEDOOR_API_KEY", "5WF0Akclk2"),
        "timeout":  45,
    },
    "blogger": {
        "blog_id":        os.environ.get("BLOGGER_BLOG_ID", ""),  # å¿…é ˆ
        "client_id":      os.environ.get("BLOGGER_CLIENT_ID", ""),
        "client_secret":  os.environ.get("BLOGGER_CLIENT_SECRET", ""),
        "refresh_token":  os.environ.get("BLOGGER_REFRESH_TOKEN", ""),
        "timeout":        45,
    },
}

# ----------------------------
# Google Sheetsèªè¨¼
# ----------------------------
def get_sheets_client():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    if not GOOGLE_APPLICATION_CREDENTIALS_JSON:
        logger.error("âŒ GOOGLE_APPLICATION_CREDENTIALS_JSON ãŒæœªè¨­å®š")
        raise RuntimeError("Googleèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
        f.write(GOOGLE_APPLICATION_CREDENTIALS_JSON)
        temp_path = f.name

    creds = ServiceAccountCredentials.from_json_keyfile_name(temp_path, scope)
    client = gspread.authorize(creds)

    try:
        os.unlink(temp_path)
    except Exception:
        pass

    return client

# ----------------------------
# ç«¶åˆä»–ç¤¾ãƒ»ãã®ä»–ãƒªãƒ³ã‚¯ç®¡ç†
# ----------------------------
def get_competitor_domains() -> List[str]:
    try:
        client = get_sheets_client()
        sheet = client.open_by_key(SPREADSHEET_ID).worksheet("ç«¶åˆä»–ç¤¾")
        competitors = sheet.get_all_values()[1:]

        domains = []
        for row in competitors:
            if row and row[0]:
                domain = row[0].strip()
                if domain.startswith("http"):
                    parsed = urlparse(domain)
                    domain = parsed.netloc
                domains.append(domain.lower())

        logger.info(f"ğŸ“‹ ç«¶åˆãƒ‰ãƒ¡ã‚¤ãƒ³ {len(domains)}ä»¶")
        return domains
    except Exception as e:
        logger.warning(f"âš ï¸ ç«¶åˆä»–ç¤¾ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def get_other_links() -> List[Dict]:
    try:
        client = get_sheets_client()
        sheet = client.open_by_key(SPREADSHEET_ID).worksheet("ãã®ä»–ãƒªãƒ³ã‚¯å…ˆ")
        rows = sheet.get_all_values()[1:]

        other_sites = []
        for row in rows:
            if len(row) >= 2 and row[0] and row[1]:
                other_sites.append({"url": row[0].strip(), "anchor": row[1].strip()})

        logger.info(f"ğŸ”— ãã®ä»–ãƒªãƒ³ã‚¯ {len(other_sites)}ä»¶")
        if not other_sites:
            other_sites = [
                {"url": "https://www.fsa.go.jp/", "anchor": "é‡‘èåº"},
                {"url": "https://www.boj.or.jp/", "anchor": "æ—¥æœ¬éŠ€è¡Œ"},
            ]
        return other_sites

    except Exception as e:
        logger.error(f"âŒ ãã®ä»–ãƒªãƒ³ã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return [
            {"url": "https://www.fsa.go.jp/", "anchor": "é‡‘èåº"},
            {"url": "https://www.boj.or.jp/", "anchor": "æ—¥æœ¬éŠ€è¡Œ"},
        ]

def choose_other_link(other_links: List[Dict], competitor_domains: List[str]) -> Optional[Dict]:
    pool = []
    for site in other_links:
        site_domain = urlparse(site["url"]).netloc.lower()
        if not any(comp in site_domain for comp in competitor_domains):
            pool.append(site)
    if pool:
        return random.choice(pool)
    return None

# ----------------------------
# Geminiè¨˜äº‹ç”Ÿæˆ
# ----------------------------
def _get_gemini_key() -> Optional[str]:
    global _gemini_idx
    if not GEMINI_KEYS:
        return None
    key = GEMINI_KEYS[_gemini_idx % len(GEMINI_KEYS)]
    _gemini_idx += 1
    return key

def call_gemini(prompt: str) -> str:
    api_key = _get_gemini_key()
    if not api_key:
        raise RuntimeError("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    endpoint = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?key={api_key}"
    payload = {"contents": [{"parts": [{"text": prompt}]}]], "generationConfig": {"temperature": 0.7}}
    r = requests.post(endpoint, json=payload, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"Gemini API ã‚¨ãƒ©ãƒ¼: {r.status_code} {r.text[:200]}")
    data = r.json()
    return data["candidates"][0]["content"]["parts"][0]["text"]

def generate_article_with_link(theme: str, url: str, anchor_text: str) -> Dict:
    if not theme or theme.strip() == "":
        theme = "é‡‘èãƒ»æŠ•è³‡ãƒ»è³‡ç”£é‹ç”¨"
        auto_theme = True
    else:
        auto_theme = False

    theme_instruction = (
        "é‡‘èç³»ï¼ˆæŠ•è³‡ã€ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã€ãƒ­ãƒ¼ãƒ³ã€è³‡ç”£é‹ç”¨ãªã©ï¼‰ã‹ã‚‰è‡ªç”±ã«ãƒ†ãƒ¼ãƒã‚’é¸ã‚“ã§"
        if auto_theme else f"ã€Œ{theme}ã€ã‚’ãƒ†ãƒ¼ãƒã«"
    )
    prompt = f"""
# å‘½ä»¤æ›¸:
{theme_instruction}ã€èª­è€…ã«ä¾¡å€¤ã®ã‚ã‚‹è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# è¨˜äº‹ã«å«ã‚ã‚‹ãƒªãƒ³ã‚¯ï¼ˆ1ã¤ã®ã¿ï¼‰:
URL: {url}
ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ: {anchor_text}

# å‡ºåŠ›å½¢å¼:
ãƒ»æœ€åˆã®è¡Œã«é­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’å‡ºåŠ›ï¼ˆã‚¿ã‚°ãªã—ï¼‰
ãƒ»ãã®å¾Œã€HTMLå½¢å¼ã§æœ¬æ–‡ä½œæˆ
ãƒ»ãƒªãƒ³ã‚¯ã‚’è‡ªç„¶ã«æŒ¿å…¥ï¼ˆ1å›ã®ã¿ï¼‰

# HTMLè¨˜æ³•:
ãƒ»è¦‹å‡ºã—: <h2>, <h3>ã®ã¿ä½¿ç”¨ï¼ˆH1ã‚¿ã‚°ã¯ä½¿ç”¨ç¦æ­¢ï¼‰
ãƒ»æ®µè½: <p>ã‚¿ã‚°ã§å›²ã‚€ï¼ˆç©ºè¡Œã¯ä»»æ„ï¼‰
ãƒ»ãƒªãƒ³ã‚¯: <a href="URL" target="_blank" rel="noopener noreferrer">ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ</a>
ãƒ»ãƒªã‚¹ãƒˆ: <ul><li>

# è¨˜äº‹ã®è¦ä»¶:
ãƒ»2000-2500æ–‡å­—
ãƒ»å°‚é–€çš„ã§ã‚ã‚ŠãªãŒã‚‰åˆ†ã‹ã‚Šã‚„ã™ã„
ãƒ»å…·ä½“çš„ãªæ•°å€¤ã‚„äº‹ä¾‹ã‚’å«ã‚ã‚‹
ãƒ»èª­è€…ã®æ‚©ã¿ã‚’è§£æ±ºã™ã‚‹å†…å®¹

# é‡è¦:
ãƒ»ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆã€‡ã€‡ãªã©ï¼‰ã¯ä½¿ç”¨ç¦æ­¢
ãƒ»ã™ã¹ã¦å…·ä½“çš„ãªå†…å®¹ã§è¨˜è¿°
ãƒ»ãƒªãƒ³ã‚¯ã¯æŒ‡å®šã•ã‚ŒãŸã‚‚ã®ã‚’æ­£ç¢ºã«ä½¿ç”¨
"""
    text = call_gemini(prompt).strip()
    lines = text.splitlines()
    title = lines[0].strip() if lines else "ã‚¿ã‚¤ãƒˆãƒ«"
    content = "\n".join(lines[1:]).strip() if len(lines) > 1 else ""
    # cleanup
    content = re.sub(r"ã€‡ã€‡|Ã—Ã—|â–³â–³", "", content)
    content = re.sub(r"ï¼ˆã“ã“ã§.*?ï¼‰", "", content)
    content = re.sub(r"<p>\s*</p>", "", content)
    return {"title": title, "content": content, "theme": (theme if not auto_theme else "é‡‘è")}

# ----------------------------
# HTMLãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ----------------------------
def enforce_anchor_attrs(html: str) -> str:
    """<a> ã« target/_blank + rel ã‚’å¼·åˆ¶ä»˜ä¸"""
    def add_attrs(m):
        tag = m.group(0)
        if re.search(r"\btarget\s*=", tag, flags=re.I) is None:
            tag = tag.replace("<a ", '<a target="_blank" ', 1)
        rel_m = re.search(r'\brel\s*=\s*"([^"]*)"', tag, flags=re.I)
        if rel_m:
            rel_val = rel_m.group(1)
            need = []
            for t in ("noopener", "noreferrer"):
                if t not in rel_val.split():
                    need.append(t)
            if need:
                new_rel = rel_val + " " + " ".join(need)
                tag = tag[:rel_m.start(1)] + new_rel + tag[rel_m.end(1):]
        else:
            tag = tag.replace("<a ", '<a rel="noopener noreferrer" ', 1)
        return tag
    return re.sub(r"<a\s+[^>]*>", add_attrs, html, flags=re.I)

# ----------------------------
# å„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æŠ•ç¨¿
# ----------------------------
def post_to_seesaa(article: dict, category_name: str = None) -> str:
    """Seesaa: XML-RPC MetaWeblogã€‚å°†æ¥æ—¥æ™‚ã¯APIåˆ¶ç´„ã«ã‚ˆã‚Šä¸‹æ›¸ãåŒ–ä¸å¯ã®ãŸã‚å³æ™‚å…¬é–‹ã®ã¿"""
    cfg = PLATFORM_CONFIGS["seesaa"]
    server = xmlrpc.client.ServerProxy(cfg["endpoint"], allow_none=True)
    safe_html = enforce_anchor_attrs(article["content"])
    content = {"title": article["title"], "description": safe_html}
    try:
        post_id = server.metaWeblog.newPost(
            cfg["blogid"], cfg["username"], cfg["password"], content, True
        )
        # ã‚«ãƒ†ã‚´ãƒªè¨­å®šï¼ˆå¯èƒ½ãªç¯„å›²ã§ï¼‰
        if category_name:
            try:
                cats = server.mt.getCategoryList(cfg["blogid"], cfg["username"], cfg["password"])
                for c in cats:
                    if c.get("categoryName") == category_name:
                        server.mt.setPostCategories(
                            post_id, cfg["username"], cfg["password"],
                            [{"categoryId": c.get("categoryId"), "isPrimary": True}]
                        )
                        break
            except Exception:
                pass
        # ãƒ‘ãƒ¼ãƒãƒªãƒ³ã‚¯å–å¾—
        try:
            post = server.metaWeblog.getPost(post_id, cfg["username"], cfg["password"])
            return post.get("permalink") or post.get("link") or f"seesaa://{post_id}"
        except Exception:
            return f"seesaa://{post_id}"
    except Exception as e:
        logger.error(f"âŒ SeesaaæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def post_to_fc2(article: dict, category_name: str = None) -> str:
    """FC2: XML-RPC MetaWeblog"""
    cfg = PLATFORM_CONFIGS["fc2"]
    server = xmlrpc.client.ServerProxy(cfg["endpoint"])
    safe_html = enforce_anchor_attrs(article["content"])
    content = {"title": article["title"], "description": safe_html}
    try:
        post_id = server.metaWeblog.newPost(
            cfg["blog_id"], cfg["username"], cfg["password"], content, True
        )
        # ã‚«ãƒ†ã‚´ãƒªè¨­å®š
        if category_name:
            try:
                cats = server.mt.getCategoryList(cfg["blog_id"], cfg["username"], cfg["password"])
                for c in cats:
                    if c.get("categoryName") == category_name:
                        server.mt.setPostCategories(post_id, cfg["username"], cfg["password"], [c])
                        break
            except Exception:
                pass
        # ä»£è¡¨URLï¼ˆå®ŸURLã¯ãƒ†ãƒ³ãƒ—ãƒ¬ä¾å­˜ã®ãŸã‚ç›®å®‰ï¼‰
        return f"https://{cfg['blog_id']}.blog.fc2.com/blog-entry-{post_id}.html"
    except Exception as e:
        logger.error(f"âŒ FC2æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def post_to_livedoor(article: dict, category_name: str = None) -> str:
    """livedoor: AtomPub"""
    cfg = PLATFORM_CONFIGS["livedoor"]
    endpoint = f"{cfg['root']}/{cfg['blog_name']}/article"
    title_xml = xml_escape(article["title"])
    safe_html = enforce_anchor_attrs(article["content"])
    content_xml = xml_escape(safe_html)
    cat_xml = f'<category term="{xml_escape(category_name)}"/>' if category_name else ""
    entry_xml = f"""<?xml version="1.0" encoding="utf-8"?>
<entry xmlns="http://www.w3.org/2005/Atom">
  <title>{title_xml}</title>
  <content type="html">{content_xml}</content>
  {cat_xml}
</entry>""".encode("utf-8")
    try:
        r = requests.post(
            endpoint,
            data=entry_xml,
            headers={"Content-Type": "application/atom+xml;type=entry"},
            auth=HTTPBasicAuth(cfg["user_id"], cfg["api_key"]),
            timeout=cfg["timeout"],
        )
        if r.status_code in (200, 201):
            try:
                root_xml = ET.fromstring(r.text)
                ns = {"atom": "http://www.w3.org/2005/Atom"}
                alt = root_xml.find(".//atom:link[@rel='alternate']", ns)
                return alt.get("href") if alt is not None else "livedoor://ok"
            except Exception:
                return "livedoor://ok"
        else:
            logger.error(f"âŒ livedooræŠ•ç¨¿å¤±æ•—: {r.status_code} {r.text[:180]}")
            return ""
    except Exception as e:
        logger.error(f"âŒ livedooræŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# ---------- Blogger ----------
def get_blogger_service():
    """Blogger API v3ï¼ˆOAuth2 ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰"""
    if not (GoogleCredentials and gapi_build and GoogleAuthRequest):
        raise RuntimeError("google-api-python-client ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚")
    cfg = PLATFORM_CONFIGS["blogger"]
    for k in ("client_id", "client_secret", "refresh_token"):
        if not cfg.get(k):
            raise RuntimeError("Blogger ã® OAuth2 ç’°å¢ƒå¤‰æ•°ï¼ˆCLIENT_ID/CLIENT_SECRET/REFRESH_TOKENï¼‰ãŒæœªè¨­å®šã§ã™ã€‚")
    creds = GoogleCredentials(
        token=None,
        refresh_token=cfg["refresh_token"],
        client_id=cfg["client_id"],
        client_secret=cfg["client_secret"],
        token_uri="https://oauth2.googleapis.com/token",
        scopes=["https://www.googleapis.com/auth/blogger"]
    )
    creds.refresh(GoogleAuthRequest())
    return gapi_build("blogger", "v3", credentials=creds, cache_discovery=False)

def post_to_blogger(article: dict, when: Optional[datetime] = None) -> str:
    """Blogger: äºˆç´„å¯ã€‚when ãŒæœªæ¥ãªã‚‰ isDraft=True + published æŒ‡å®š"""
    cfg = PLATFORM_CONFIGS["blogger"]
    blog_id = cfg.get("blog_id") or ""
    if not blog_id:
        logger.error("âŒ BLOGGER_BLOG_ID ãŒæœªè¨­å®šã§ã™")
        return ""
    try:
        svc = get_blogger_service()
        body = {
            "kind": "blogger#post",
            "title": article["title"],
            "content": enforce_anchor_attrs(article["content"]),
        }
        is_draft = bool(when and when > datetime.now())
        if is_draft:
            # Bloggerã¯ published ã«æœªæ¥æ™‚åˆ»ã‚’å…¥ã‚Œã¤ã¤ isDraft=True ã§äºˆç´„ï¼ˆå®Ÿéš›ã®å‹•ä½œã¯ãƒ†ãƒ³ãƒ—ãƒ¬/è¨­å®šã«ä¾å­˜ï¼‰
            body["published"] = when.isoformat()
        post = svc.posts().insert(blogId=blog_id, body=body, isDraft=is_draft).execute()
        url = post.get("url", "")
        logger.info(f"âœ… BloggeræŠ•ç¨¿æˆåŠŸ: {url or '(draft)'}")
        return url or "blogger://draft"
    except Exception as e:
        logger.error(f"âŒ BloggeræŠ•ç¨¿å¤±æ•—: {e}\n{traceback.format_exc()}")
        return ""

# ----------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ----------------------------
def get_value_safe(row: List[str], idx: int) -> str:
    return row[idx].strip() if len(row) > idx and row[idx] else ""

def to_int_safe(s: str, default: int = 0) -> int:
    try:
        return int(s)
    except Exception:
        return default

def get_max_posts_for_project(project_key: str, post_target: str = "") -> int:
    cfg = NON_WP_PROJECTS[project_key]
    max_posts = cfg["max_posts"]
    if isinstance(max_posts, dict):
        if post_target.lower() == "livedoor":
            return max_posts.get("livedoor", 15)
        if post_target.lower() == "blogger":
            return max_posts.get("blogger", 20)
        return max(max_posts.values()) if max_posts else 20
    return int(max_posts)

def parse_time_cell(s: str) -> Optional[datetime]:
    s = (s or "").strip()
    if not s:
        return None
    # 1) YYYY/MM/DD HH:MM
    for fmt in ("%Y/%m/%d %H:%M", "%Y-%m-%d %H:%M"):
        try:
            return datetime.strptime(s, fmt)
        except Exception:
            pass
    # 2) ISO 8601
    try:
        return datetime.fromisoformat(s)
    except Exception:
        pass
    # 3) HH:MMï¼ˆå½“æ—¥/éãã¦ã„ã‚Œã°ç¿Œæ—¥ï¼‰
    m = re.match(r"^(\d{1,2}):(\d{2})$", s)
    if m:
        h, M = int(m.group(1)), int(m.group(2))
        now = datetime.now()
        d = now.replace(hour=h, minute=M, second=0, microsecond=0)
        return d if d >= now else d + timedelta(days=1)
    return None

# ----------------------------
# æŠ•ç¨¿å®Ÿè¡Œã‚³ã‚¢
# ----------------------------
def execute_scheduled_post(
    row: List[str],
    project_key: str,
    sheet,
    row_idx: int,
    col_idx: int,
    other_links: List[Dict],
    competitor_domains: List[str]
) -> bool:
    """
    å˜ä¸€ã®äºˆç´„æŠ•ç¨¿ã‚’å®Ÿè¡Œï¼ˆå®Œå…¨ãƒ­ã‚°è¨˜éŒ²å¯¾å¿œï¼‰
    åˆ—ä»•æ§˜ï¼ˆæƒ³å®šï¼‰:
      A:ãƒ†ãƒ¼ãƒ(0) / B:å®£ä¼URL(1) / C:æŠ•ç¨¿å…ˆ(2) / D:ã‚¢ãƒ³ã‚«ãƒ¼(3) / E:ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹(4) /
      F:æœ€çµ‚URL(6) / G:ã‚«ã‚¦ãƒ³ã‚¿(6) / H:(7)ã‚«ãƒ†ã‚´ãƒª / I:(8)å®Œäº†æ™‚åˆ» / Kä»¥é™=äºˆç´„
    """
    try:
        cfg = NON_WP_PROJECTS[project_key]

        # ç¾åœ¨ã‚«ã‚¦ãƒ³ã‚¿ï¼ˆGåˆ—=7ï¼‰
        current_counter = to_int_safe(get_value_safe(row, 6), 0)

        # æŠ•ç¨¿å…ˆï¼ˆCåˆ—=3ï¼‰æœªæŒ‡å®šã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…ˆé ­
        post_target = (get_value_safe(row, 2) or (cfg["platforms"][0] if cfg["platforms"] else "")).lower()
        max_posts = get_max_posts_for_project(project_key, post_target)

        if current_counter >= max_posts:
            logger.info(f"âš ï¸ æ—¢ã« {max_posts} è¨˜äº‹å®Œäº†æ¸ˆã¿ - ã‚¹ã‚­ãƒƒãƒ—")
            return False

        # è¨˜äº‹å†…å®¹ï¼ˆæœ€çµ‚è¨˜äº‹ã¯å®£ä¼URLã€ãã‚Œä»¥å‰ã¯ãã®ä»–ãƒªãƒ³ã‚¯ï¼‰
        if current_counter == max_posts - 1:
            logger.info(f"ğŸ“Š {max_posts}æœ¬ç›® â†’ å®£ä¼URLä½¿ç”¨")
            url = get_value_safe(row, 1)
            anchor = get_value_safe(row, 3) or project_key
            category = get_value_safe(row, 7) if len(row) >= 8 else None
        else:
            logger.info(f"ğŸ“Š {current_counter + 1}æœ¬ç›® â†’ ãã®ä»–ãƒªãƒ³ã‚¯ä½¿ç”¨")
            chosen_link = choose_other_link(other_links, competitor_domains)
            if not chosen_link:
                logger.error("âŒ ãã®ä»–ãƒªãƒ³ã‚¯ãŒç©ºã§ã™")
                return False
            url = chosen_link["url"]
            anchor = chosen_link["anchor"]
            category = "ãŠé‡‘ã®ãƒãƒ¡çŸ¥è­˜"

        # è¨˜äº‹ç”Ÿæˆ
        logger.info("ğŸ§  è¨˜äº‹ç”Ÿæˆä¸­...")
        theme = get_value_safe(row, 0) or "é‡‘èãƒ»æŠ•è³‡ãƒ»è³‡ç”£é‹ç”¨"
        article = generate_article_with_link(theme, url, anchor)
        logger.info(f"ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«: {article['title']} / ğŸ”— {anchor}")

        posted_urls: List[str] = []

        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥æŠ•ç¨¿
        if "seesaa" in cfg["platforms"] and (not post_target or post_target == "seesaa"):
            logger.info("ğŸ“¤ Seesaa æŠ•ç¨¿...")
            u = post_to_seesaa(article, category)
            if u:
                posted_urls.append(u)
                logger.info(f"âœ… Seesaa æˆåŠŸ: {u}")

        if "fc2" in cfg["platforms"] and (not post_target or post_target == "fc2"):
            logger.info("ğŸ“¤ FC2 æŠ•ç¨¿...")
            u = post_to_fc2(article, category)
            if u:
                posted_urls.append(u)
                logger.info(f"âœ… FC2 æˆåŠŸ: {u}")

        if "livedoor" in cfg["platforms"] and (not post_target or post_target == "livedoor"):
            logger.info("ğŸ“¤ livedoor æŠ•ç¨¿...")
            u = post_to_livedoor(article, category)
            if u:
                posted_urls.append(u)
                logger.info(f"âœ… livedoor æˆåŠŸ: {u}")

        if "blogger" in cfg["platforms"] and (not post_target or post_target == "blogger"):
            logger.info("ğŸ“¤ Blogger æŠ•ç¨¿...")
            # Kåˆ—æ™‚åˆ»ï¼äºˆç´„ï¼ˆæœªæ¥ï¼‰ã®å ´åˆã¯ Blogger ã®ã¿äºˆç´„å¯¾å¿œ
            u = post_to_blogger(article, when=None)
            if u:
                posted_urls.append(u)
                logger.info(f"âœ… Blogger æˆåŠŸ: {u}")

        if not posted_urls:
            logger.error("âŒ å…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æŠ•ç¨¿å¤±æ•—")
            return False

        # åæ˜ ãƒ»è¨˜éŒ²
        new_counter = current_counter + 1
        timestamp = datetime.now().strftime("%Y/%m/%d %H:%M:%S")
        for u in posted_urls:
            logger.info(f"ğŸ“‹ è¨˜éŒ²: #{new_counter} {article['title']} â†’ {u} @ {timestamp}")

        # Gåˆ—=7: ã‚«ã‚¦ãƒ³ã‚¿æ›´æ–°
        sheet.update_cell(row_idx, 7, str(new_counter))
        # Kåˆ— è©²å½“ã‚»ãƒ«ã‚’ã€Œå®Œäº†ã€ã«
        sheet.update_cell(row_idx, col_idx, "å®Œäº†")

        # æœ€çµ‚è¨˜äº‹å®Œäº†æ™‚ã®å‡¦ç†
        if new_counter >= max_posts:
            # Eåˆ—=5: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
            sheet.update_cell(row_idx, 5, "å‡¦ç†æ¸ˆã¿")
            # Fåˆ—=6: æœ€çµ‚è¨˜äº‹URL
            sheet.update_cell(row_idx, 6, ", ".join(posted_urls))
            # Iåˆ—=9: å®Œäº†æ—¥æ™‚
            sheet.update_cell(row_idx, 9, datetime.now().strftime("%Y/%m/%d %H:%M"))
            logger.info(f"ğŸ¯ {project_key} è¡Œ{row_idx} å®Œäº†ï¼ˆ{max_posts}æœ¬é”æˆï¼‰")
        else:
            logger.info(f"ğŸ“Š ã‚«ã‚¦ãƒ³ã‚¿æ›´æ–°: {new_counter}")

        return True

    except Exception as e:
        logger.error(f"âŒ æŠ•ç¨¿å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")
        return False

# ----------------------------
# Kåˆ—ãƒã‚§ãƒƒã‚¯
# ----------------------------
def check_and_execute_k_column_schedules(window_minutes: int = 30, target_projects: dict = None) -> Dict[str, int]:
    """
    Kåˆ—äºˆç´„æŠ•ç¨¿ãƒã‚§ãƒƒã‚¯ï¼†å®Ÿè¡Œï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œï¼‰
    """
    if target_projects is None:
        target_projects = NON_WP_PROJECTS

    logger.info("â° Kåˆ—äºˆç´„æŠ•ç¨¿ãƒã‚§ãƒƒã‚¯é–‹å§‹")
    client = get_sheets_client()
    now = datetime.now()
    window_end = now + timedelta(minutes=window_minutes)

    competitor_domains = get_competitor_domains()
    other_links = get_other_links()

    executed_total = 0
    skipped_total = 0

    for project_key, cfg in target_projects.items():
        try:
            logger.info(f"ğŸ“‹ {project_key} ({cfg['worksheet']}) ãƒã‚§ãƒƒã‚¯ä¸­...")
            sheet = client.open_by_key(SPREADSHEET_ID).worksheet(cfg["worksheet"])
            rows = sheet.get_all_values()

            if len(rows) <= 1:
                logger.info(f"âš ï¸ {cfg['worksheet']} ã«ãƒ‡ãƒ¼ã‚¿ãªã—")
                continue

            for row_idx, row in enumerate(rows[1:], start=2):
                # æ—¢ã«å‡¦ç†æ¸ˆã¿ã¯ã‚¹ã‚­ãƒƒãƒ—
                if get_value_safe(row, 4) == "å‡¦ç†æ¸ˆã¿":
                    continue

                # Kåˆ—(11)ä»¥é™ã®äºˆç´„ã‚»ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                for col_idx0 in range(10, len(row)):
                    val = (row[col_idx0] or "").strip()
                    if not val or val == "å®Œäº†":
                        continue

                    scheduled_time = parse_time_cell(val)
                    if not scheduled_time:
                        continue

                    # å®Ÿè¡Œå¯¾è±¡ï¼ˆä»Šã€œã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ï¼‰
                    if now <= scheduled_time <= window_end:
                        logger.info(f"ğŸš€ å®Ÿè¡Œå¯¾è±¡: {project_key} è¡Œ{row_idx} åˆ—{col_idx0+1} {scheduled_time:%Y/%m/%d %H:%M}")
                        ok = execute_scheduled_post(
                            row=row,
                            project_key=project_key,
                            sheet=sheet,
                            row_idx=row_idx,
                            col_idx=col_idx0 + 1,  # gspreadã¯1å§‹ã¾ã‚Š
                            other_links=other_links,
                            competitor_domains=competitor_domains
                        )
                        if ok:
                            executed_total += 1
                            # é€£æŠ•é˜²æ­¢ï¼ˆ3æŠ•ç¨¿ã”ã¨ã«ä¼‘æ†©ï¼‰
                            if executed_total % 3 == 0:
                                wait = random.randint(MIN_INTERVAL, MAX_INTERVAL)
                                logger.info(f"â³ é€£æŠ•é˜²æ­¢: {wait}ç§’å¾…æ©Ÿ")
                                time.sleep(wait)
                        else:
                            skipped_total += 1

        except Exception as e:
            logger.error(f"âŒ {project_key} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")

    logger.info(f"â° Kåˆ—äºˆç´„ãƒã‚§ãƒƒã‚¯å®Œäº†: å®Ÿè¡Œ {executed_total} / ã‚¹ã‚­ãƒƒãƒ— {skipped_total}")
    return {"executed": executed_total, "skipped": skipped_total}

# ----------------------------
# ãƒ¡ã‚¤ãƒ³
# ----------------------------
def main():
    parser = argparse.ArgumentParser(description="Kåˆ—äºˆç´„æŠ•ç¨¿å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆGitHub Actionsç”¨ï¼‰")
    parser.add_argument("--window", type=int, default=30, help="å®Ÿè¡Œã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆåˆ†ï¼‰")
    parser.add_argument("--test", action="store_true", help="ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆæŠ•ç¨¿ã—ãªã„ï¼‰")
    parser.add_argument("--project", type=str, help="ç‰¹å®šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼ˆbiggift / arigatayaï¼‰")

    args = parser.parse_args()

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    target_projects = NON_WP_PROJECTS
    if args.project:
        if args.project in NON_WP_PROJECTS:
            target_projects = {args.project: NON_WP_PROJECTS[args.project]}
            logger.info(f"ğŸ¯ ç‰¹å®šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œ: {args.project}")
        else:
            logger.error(f"âŒ ä¸æ˜ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {args.project}")
            exit(1)

    if args.test:
        logger.info("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é–‹å§‹ï¼ˆæŠ•ç¨¿ã¯è¡Œã„ã¾ã›ã‚“ï¼‰")
        try:
            client = get_sheets_client()
            logger.info("âœ… Google Sheets æ¥ç¶šOK")
            competitor_domains = get_competitor_domains()
            other_links = get_other_links()
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—: ç«¶åˆ {len(competitor_domains)} / ãã®ä»– {len(other_links)}")
            for k in target_projects:
                logger.info(f"ğŸ“‹ å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {k}")
            logger.info("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            exit(1)
        return

    logger.info(f"ğŸš€ Kåˆ—äºˆç´„æŠ•ç¨¿ãƒã‚§ãƒƒã‚¯é–‹å§‹: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦={args.window}åˆ†")
    logger.info("ğŸ“‹ å®Ÿè¡Œå¯¾è±¡: " + (args.project if args.project else f"å…¨({', '.join(NON_WP_PROJECTS.keys())})"))

    try:
        result = check_and_execute_k_column_schedules(window_minutes=args.window, target_projects=target_projects)
        logger.info(f"âœ… å‡¦ç†å®Œäº†: {result}")
        # GitHub Actions å‡ºåŠ›ï¼ˆæ—§ set-output ã¯éæ¨å¥¨ã ãŒæ—¢å­˜äº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
        print(f"::set-output name=executed::{result['executed']}")
        print(f"::set-output name=skipped::{result['skipped']}")
    except Exception as e:
        logger.error(f"âŒ ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")
        exit(1)

if __name__ == "__main__":
    main()
